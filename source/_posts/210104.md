---
title: Python实训-Day5(爬虫基础)
toc: true
reward: true
copyright: true
article_type: 0
tags:
  - Python
abbrlink: '67e49784'
date: 2021-01-04 18:58:28
---

![u=2017100131gp=0](https://cdn.jsdelivr.net/gh/Anyway521/blogpic2@main/image/u=2017100131gp=0.jpg)

<!-- more -->

### 1、王者荣耀皮肤爬取

``` python
import os
import requests
import time
if os.path.exists("王者荣耀皮肤") == False:
    os.makedirs("王者荣耀皮肤")

url = "https://pvp.qq.com/web201605/js/herolist.json"
r = requests.get(url)
herolist = r.json()
for item in herolist:
    # 判断是否有皮肤
    if "skin_name" in item.keys():
        #英雄编号
        ename = item["ename"]
        #英雄名称
        cname = item["cname"]
        print("%s皮肤正在下载........."%cname)
        skin_name = item["skin_name"]
        skin_name_list = skin_name.split('|')
        # 遍历列表
        print(skin_name_list)
        for i in range(len(skin_name_list)):
            skin_url = "https://game.gtimg.cn/images/yxzj/img201606/skin/hero/%s/%s-bigskin-%d.jpg"%(ename,ename,i)
            with open("王者荣耀皮肤/%s[%s].jpg"%(cname,skin_name_list[i]),"wb") as file:
                file.write(requests.get(skin_url).content)
                print("%s[%s]下载成功!!"%(cname,skin_name_list[i]))
            time.sleep(1)

```

### 2、爱思助手铃声爬取
``` python
import  requests
from bs4 import BeautifulSoup
from urllib import request
import os
import ssl
ssl.create_default_https_context = ssl._create_unverified_context  #验证SSL

if __name__ == '__main__':
    # 创建文件夹
    k = os.path.exists("爱思助手铃声")
    if k == False:
        os.makedirs("爱思助手铃声")
    for i in range(1,4):
        url = "https://www.i4.cn/ring_23_0_%d.html"%i
        # print(url)
        res = requests.get(url)
        # print(res.status_code)
        html = res.text
        bf = BeautifulSoup(html,"lxml")
        music_list = bf.find_all("div",class_ = "list ring_list")
        for item in music_list:
            btitem = BeautifulSoup(str(item),"lxml")
            tit = btitem.find("div",class_ = "title")
            name = tit.string
            # print(name)
            btn = btitem.find("div",class_ = "btn audio_play")
            music_url = btn.get("data-mp3")
            with open("爱思助手铃声/%s.mp3"%name,"wb") as file:
                file.write(requests.get(url=music_url).content)
            print("%s下载成功"%name)
            # request.urlretrieve(url=music_url,filename="爱思助手铃声/%s.mp3"%name)

```

### 3、风景图片再爬取
``` python
import os
import requests
from bs4 import BeautifulSoup
import time

def getHTMLtext(url):
    try:
        r = requests.get(url)
        r.encoding = r.apparent_encoding
        return r.text
    except:
        return "产生异常"


if __name__ == '__main__':
    # 共278页，自己选择下载的页数
    url = "http://www.bizhi88.com/s/1/1.html"
    if os.path.exists("风景图片") == False:
        os.makedirs("风景图片")
    index = 0    #用于下载的图片命名
    for i in range(1,10):   #先下载10页的
        url_per_page = "http://www.bizhi88.com/s/1/%d.html"%i
        per_page = getHTMLtext(url_per_page)
        per_page_bf = BeautifulSoup(per_page,"lxml")
        per_page_images = per_page_bf.find_all("img",class_="lazy")
        for item in per_page_images:
            temp = item.get("data-original")
            url_len = len(temp)-1
            url_per_image = temp[0:url_len]
            with open("风景图片/%d.jpg"%index,"wb") as file:
                file.write(requests.get(url_per_image).content)
                index+=1

```
### What I Leant?
``` python
    1、bs4的find_all()用法
    2、lxml
    3、文件存储时文件的命名方法
```

_(¦3」∠)_